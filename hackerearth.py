# -*- coding: utf-8 -*-
"""HackerEarth_sai.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17J5zLIXjLVruroWT7ARDZPQQ-zsS1b5D
"""



# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import pandas as pd
import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.layers import  AveragePooling2D, MaxPooling2D
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import optimizers
from tensorflow.keras.applications.inception_v3 import InceptionV3
from keras.layers.core import Dropout

data = pd.read_csv("train.csv")

test = pd.read_csv("test.csv")

temp ={'Food': 0,'Attire': 1 ,'Decorationandsignage' : 2,'misc' : 3 } 
data.Class = [temp[item] for item in data.Class] 

inv_map = {0: 'Food', 1:'Attire', 2:'Decorationandsignage', 3:'misc'}

old_X = []
for item in data.Image:
     img = cv2.imread('Train Images/'+item)
     img = cv2.resize(img,(150,150))
     img = img.astype('float32')
     old_X.append(img)

test_data = []
for item in test.Image:
     img = cv2.imread('Test Images/'+item)
     img = cv2.resize(img,(150,150))
     img = img.astype('float32')
     test_data.append(img)

X = np.array(old_X)
test_final= np.array(test_data)

Y = data["Class"]
Y = np.array(Y)

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.33,random_state = 34)

plt.imshow(X_train[33])

X_train[1].shape



#np.set_printoptions(threshold=np.inf)
#to see whole array values

#test_img = [cv2.resize(test[i],new_size) for i in  range(len(test.Image)) ]

Y_train = to_categorical(Y_train)

Y_test = to_categorical(Y_test)

Y_test.shape

print(X_train.shape,X_test.shape,Y_train.shape)

# # # # model = Sequential()
# # # # model.add(Conv2D(256, kernel_size=3, activation='relu',kernel_initializer='glorot_uniform', input_shape=(80,80,3)))
# # # # model.add(AveragePooling2D(pool_size=(3, 3), strides=(1,1), padding='valid', data_format=None))
# # # # # model.add(Conv2D(64, kernel_size=5, activation='relu',kernel_initializer='glorot_uniform'))
# # # # # model.add(AveragePooling2D(pool_size=(2, 2), strides=(1,1), padding='valid', data_format=None))
# # # # model.add(Conv2D(8, kernel_size=3, activation='relu',kernel_initializer='glorot_uniform'))
# # # #model.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='valid', data_format=None))
# # # model = VGG16()
# # # # remove the output layer
# # # model.layers.pop()
# # # #model = Model(inputs=model.inputs, outputs=model.layers[-1].output)
# # # flat1 = Flatten()(model.outputs)
# # # output = Dense(10, activation='softmax')(flat1)

# # # #model.add(Flatten())
# # # model.add(Dense(4, activation='softmax'))



# # model = VGG16(include_top=False, input_shape=(150, 150, 3))
# # # add new classifier layers
# # flat1 = Flatten()(model.outputs)
# # class1 = Dense(1024, activation='relu')(flat1)
# # output = Dense(10, activation='softmax')(class1)
# # # define new model
# # model = Model(inputs=model.inputs, outputs=output)


# model = models.Sequential()
# model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(8, (3, 3), activation='relu'))
# model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Conv2D(2, (3, 3), activation='relu'))
# model.add(layers.Flatten())
# model.add(layers.Dense(128, activation='relu'))
# model.add(layers.Dense(64, activation='relu'))
# model.add(layers.Dense(16, activation='relu'))
# model.add(layers.Dense(4, activation='softmax'))

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150,3))
base_model.trainable = False

x = base_model.output
x = layers.GlobalAveragePooling2D()(x)
# let's add a fully-connected layer
#x = Dropout(0.5)(x)
# and a sofymax/logistic layer -- we have 6 classes
#x=layers.Conv2D(64, (3, 3), activation='relu')(x)
#x=layers.MaxPooling2D((4,4))(x)
#x=layers.Dense(64, activation='relu')(x)
x=layers.Dense(32, activation='relu')(x)
predictions = layers.Dense(4, activation='softmax')(x)

# this is the model we will train
model = Model(inputs=base_model.inputs, outputs=predictions)


#model.summary()

adm = optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False)

model.compile(optimizer = adm, loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=20)

labels = model.predict(test_final)

label = [np.argmax(i) for i in labels]
class_label = [inv_map[x] for x in label]
#print(class_label[:3])
submission = pd.DataFrame({ 'Image': test.Image, 'Class': class_label })
submission.head(10)
submission.to_csv('submission.csv', index=False)


